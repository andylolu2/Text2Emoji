{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Text2Emoji ([More info](/../../README.md))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Huggingface models to ONNX for faster inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andylo/Projects/Text2Emoji/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime-tools in ./.venv/lib/python3.8/site-packages (1.7.0)\n",
      "Requirement already satisfied: onnxruntime-gpu in ./.venv/lib/python3.8/site-packages (1.7.0)\n",
      "Requirement already satisfied: onnx in ./.venv/lib/python3.8/site-packages (1.8.1)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (7.0.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (20.9)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (5.8.0)\n",
      "Requirement already satisfied: py3nvml in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (0.2.6)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (15.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from onnxruntime-tools) (1.20.1)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.8/site-packages (from onnxruntime-gpu) (3.15.6)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.8/site-packages (from onnx) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./.venv/lib/python3.8/site-packages (from onnx) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging->onnxruntime-tools) (2.4.7)\n",
      "Requirement already satisfied: xmltodict in ./.venv/lib/python3.8/site-packages (from py3nvml->onnxruntime-tools) (0.12.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.8/site-packages (from coloredlogs->onnxruntime-tools) (9.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-tools onnxruntime-gpu onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 13\n",
      "Loading pipeline (model: distilbert-base-uncased, tokenizer: distilbert-base-uncased)\n",
      "Creating folder models/onnx/distilbert\n",
      "Using framework PyTorch: 1.8.1+cu102\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n",
      "ONNX opset version set to: 13\n",
      "Loading pipeline (model: sentence-transformers/distilbert-base-nli-stsb-mean-tokens, tokenizer: sentence-transformers/distilbert-base-nli-stsb-mean-tokens)\n",
      "Creating folder models/onnx/sentence-transformer\n",
      "Using framework PyTorch: 1.8.1+cu102\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
      "Ensuring inputs are in correct order\n",
      "head_mask is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "!rm -rf models/\n",
    "from pathlib import Path\n",
    "from transformers.convert_graph_to_onnx import convert\n",
    "from config import PrepConfig\n",
    "\n",
    "# Handles all the above steps for you\n",
    "convert(framework=\"pt\", model=PrepConfig.DISTILBERT_NAME, output=Path(PrepConfig.DISTILBERT_ONNX_PATH), opset=13)\n",
    "convert(framework=\"pt\", model=PrepConfig.SENTENCE_TRANSFORMER_NAME, output=Path(PrepConfig.SENTENCE_ONNX_PATH), opset=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "from config import PrepConfig\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import dataclass\n",
    "from time import time\n",
    "from tqdm import trange\n",
    "\n",
    "# Constants from the performance optimization available in onnxruntime\n",
    "# It needs to be done before importing onnxruntime\n",
    "environ[\"OMP_NUM_THREADS\"] = str(cpu_count(logical=True))\n",
    "environ[\"OMP_WAIT_POLICY\"] = 'ACTIVE'\n",
    "\n",
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions, get_all_providers\n",
    "\n",
    "def create_model_for_provider(model_path: str, provider: str) -> InferenceSession: \n",
    "  \n",
    "  assert provider in get_all_providers(), f\"provider {provider} not found, {get_all_providers()}\"\n",
    "\n",
    "  # Few properties that might have an impact on performances (provided by MS)\n",
    "  options = SessionOptions()\n",
    "  options.intra_op_num_threads = 1\n",
    "  options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "  # Load the model as a graph and prepare the CPU backend \n",
    "  session = InferenceSession(model_path, options, providers=[provider])\n",
    "  session.disable_fallback()\n",
    "    \n",
    "  return session\n",
    "  \n",
    "\n",
    "@contextmanager\n",
    "def track_infer_time(buffer: [int]):\n",
    "    start = time()\n",
    "    yield\n",
    "    end = time()\n",
    "\n",
    "    buffer.append(end - start)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OnnxInferenceResult:\n",
    "  model_inference_time: [int]  \n",
    "  optimized_model_path: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "test_text = PrepConfig.SAMPLE_TEXT\n",
    "model_inputs = tokenizer([\" \".join([test_text]*i) for i in range(1, 2)], \n",
    "    return_tensors=\"np\",\n",
    "    padding=True,\n",
    "    truncation=True)\n",
    "inputs_onnx = dict(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: GPU\n",
      "ONNX models loaded\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "print(f\"Device: {onnxruntime.get_device()}\")\n",
    "distilbert_onnx = create_model_for_provider(PrepConfig.DISTILBERT_ONNX_PATH, \"CUDAExecutionProvider\")\n",
    "sentence_onnx = create_model_for_provider(PrepConfig.SENTENCE_ONNX_PATH, \"CUDAExecutionProvider\")\n",
    "print(\"ONNX models loaded\")\n",
    "# print(distilbert_onnx.run(None, inputs_onnx)[0])\n",
    "# print(mean_pooling(sentence_onnx.run(None, inputs_onnx), inputs_onnx['attention_mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tracking distilbert inference time on CUDA: 100%|██████████| 100/100 [00:00<00:00, 318.31it/s]\n",
      "Tracking sentence transformer inference time on CUDA: 100%|██████████| 100/100 [00:00<00:00, 323.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import onnx\n",
    "from onnxruntime.quantization import QuantizationMode\n",
    "from transformers.convert_graph_to_onnx import quantize\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from config import PrepConfig\n",
    "\n",
    "#mean pooling - take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    '''\n",
    "    model_output dimensions: (1, BATCH_SIZE, SEQ_LEN, HIDDEN_DIM_SIZE)\n",
    "    '''\n",
    "    token_embeddings = model_output[0]\n",
    "    assert isinstance(token_embeddings, np.ndarray)\n",
    "    if isinstance(attention_mask, np.ndarray):\n",
    "        input_mask_expanded = np.tile(np.expand_dims(attention_mask, axis=-1), (1, 1, token_embeddings.shape[-1])).astype('float32')\n",
    "    else:\n",
    "        assert isinstance(attention_mask, torch.tensor)\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "    sum_embeddings = np.sum(token_embeddings * input_mask_expanded, axis=1)\n",
    "    sum_mask = np.clip(np.sum(input_mask_expanded, axis=1), a_max=None, a_min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# Keep track of the inference time\n",
    "time_buffer = []\n",
    "\n",
    "provider = \"CUDA\"\n",
    "\n",
    "# Warm up the model\n",
    "word_embeddings = distilbert_onnx.run(None, inputs_onnx)\n",
    "sentence_embeddings = mean_pooling(\n",
    "    sentence_onnx.run(None, inputs_onnx), \n",
    "    attention_mask=inputs_onnx['attention_mask'])\n",
    "\n",
    "# Compute \n",
    "for _ in trange(100, desc=f\"Tracking distilbert inference time on {provider}\"):\n",
    "    with track_infer_time(time_buffer):\n",
    "        assert np.array_equal(word_embeddings, distilbert_onnx.run(None, inputs_onnx))\n",
    "\n",
    "for _ in trange(100, desc=f\"Tracking sentence transformer inference time on {provider}\"):\n",
    "    with track_infer_time(time_buffer):\n",
    "        assert np.array_equal(sentence_embeddings, mean_pooling(\n",
    "            sentence_onnx.run(None, inputs_onnx), \n",
    "            attention_mask=inputs_onnx['attention_mask']\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare emoji vocab dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original no. of emojis: 4581\n",
      "cleaned no. of emojis: 1752\n",
      "Longest emoji vocab: 🇬🇸 South Georgia & South Sandwich Islands\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from config import PrepConfig\n",
    "\n",
    "df = pd.read_csv('data/emojis/emoji_df.csv', usecols=['emoji', 'name'])\n",
    "original_len = len(df)\n",
    "emoji_vocab = set(df['name'].to_list())\n",
    "\n",
    "def clean_names(row):\n",
    "    t = row['name']\n",
    "    flag_re = r\"flag: (.*)\"\n",
    "    is_flag = re.match(flag_re, t)\n",
    "    if is_flag:\n",
    "        # remove flag prefixes\n",
    "        row['cleaned_name'] = is_flag[1]\n",
    "        return row\n",
    "    details_re = r\"(.*): (.*)\"\n",
    "    is_detailed = re.match(details_re, t)\n",
    "    if is_detailed:\n",
    "        # remove skin tone adjective\n",
    "        row['cleaned_name'] = is_detailed[1]\n",
    "        return row\n",
    "    row['cleaned_name'] = row['name']\n",
    "    return row\n",
    "\n",
    "df = df.apply(clean_names, axis=1)\\\n",
    "    .drop_duplicates(subset=['cleaned_name'], ignore_index=True)\n",
    "\n",
    "print(f\"Original no. of emojis: {original_len}\")\n",
    "print(f\"cleaned no. of emojis: {len(df)}\")\n",
    "longest_arg = df['cleaned_name'].str.len().argmax()\n",
    "print(f\"Longest emoji vocab: {df['emoji'].iloc[longest_arg]} {df['cleaned_name'].iloc[longest_arg]}\")\n",
    "\n",
    "df.to_csv(PrepConfig.EMOJI_VOCAB_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in ./.venv/lib/python3.8/site-packages (3.6.1)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in ./.venv/lib/python3.8/site-packages (from tables) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.3 in ./.venv/lib/python3.8/site-packages (from tables) (1.20.1)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.2.1-cp38-cp38-manylinux1_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 8.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.5; python_version == \"3.8\" in ./.venv/lib/python3.8/site-packages (from h5py) (1.20.1)\n",
      "Installing collected packages: h5py\n",
      "Successfully installed h5py-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tables\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 65.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from config import PrepConfig\n",
    "import h5py\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def body_to_embeddings(sub_df, pbar):\n",
    "    input_ids = np.stack(sub_df['input_ids'].to_numpy())\n",
    "    mask = np.stack(sub_df['attention_mask'].to_numpy())\n",
    "    inputs = {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': mask,\n",
    "    }\n",
    "    word = distilbert_onnx.run(None, inputs)[0]\n",
    "    sentence = mean_pooling(sentence_onnx.run(None, inputs), mask)\n",
    "    sub_df['word_embeddings'] = list(word)\n",
    "    sub_df['sentence_embeddings'] = list(sentence)\n",
    "    pbar.update(len(sub_df))\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "def split_dataframe(df, chunk_size = 1000): \n",
    "    num_chunks = math.ceil(len(df) / chunk_size)\n",
    "    for i in range(num_chunks):\n",
    "        yield df[i*chunk_size:(i+1)*chunk_size]\n",
    "\n",
    "\n",
    "sql_conn = sqlite3.connect('data/reddit-comments/database.sqlite')\n",
    "comments = pd.read_sql_query(\n",
    "    \"SELECT body FROM May2015 LIMIT(12000)\", \n",
    "    con=sql_conn)\n",
    "# Full dataset has about 54,000,000 entries\n",
    "\n",
    "comments = comments.drop_duplicates(subset=['body'], ignore_index=True)\n",
    "comments = comments[comments['body'].str.count(r'[\\u0000-\\u007F]') >= (comments['body'].str.len() * PrepConfig.ENGLISH_THRESHOLD)]\n",
    "comments = comments.reset_index(drop=True)  # Discard non-English entries\n",
    "!rm {PrepConfig.H5DSET_PATH}  # rm existing\n",
    "with tqdm(total=len(comments)) as pbar:\n",
    "    with h5py.File(PrepConfig.H5DSET_PATH, \"w\") as f:\n",
    "        training_group = f.create_group('training')\n",
    "        training_group.attrs['max_len'] = PrepConfig.MAX_LEN\n",
    "        testing_group = f.create_group('testing')\n",
    "        testing_group.attrs['max_len'] = PrepConfig.MAX_LEN\n",
    "        fields = ['body', 'mask', 'word', 'sentence']\n",
    "        h5dset = {\n",
    "            'train': {\n",
    "                'group': training_group,\n",
    "                **{field: None for field in fields}\n",
    "            },\n",
    "            'test': {\n",
    "                'group': testing_group,\n",
    "                **{field: None for field in fields}\n",
    "            },\n",
    "        }\n",
    "        for chunk in split_dataframe(comments, PrepConfig.PD_CHUNK_SIZE):\n",
    "            encodings = tokenizer(\n",
    "                chunk['body'].to_list(), \n",
    "                max_length=PrepConfig.MAX_LEN,\n",
    "                padding='max_length', \n",
    "                truncation=True, \n",
    "                return_tensors='np')\n",
    "            chunk['input_ids'] = list(encodings.input_ids)\n",
    "            chunk['attention_mask'] = list(encodings.attention_mask)\n",
    "            chunk = chunk.groupby(np.arange(len(chunk)) // PrepConfig.BATCH_SIZE)\\\n",
    "                .apply(lambda x: body_to_embeddings(x, pbar)).reset_index(drop=True)\n",
    "            data = {\n",
    "                'body': chunk['body'].to_numpy(),\n",
    "                'mask': np.stack(chunk['attention_mask'].to_numpy()),\n",
    "                'word': np.stack(chunk['word_embeddings'].to_numpy()),\n",
    "                'sentence': np.stack(chunk['sentence_embeddings'].to_numpy())\n",
    "            }\n",
    "            lengths = [len(data[key]) for key in data]\n",
    "            assert all([x == lengths[0] for x in lengths])\n",
    "            if pbar.n < len(comments) * (1-PrepConfig.TESTING_SPLIT):\n",
    "                output_target = h5dset['train']\n",
    "            else:\n",
    "                output_target = h5dset['test']\n",
    "            if output_target['word'] is None:\n",
    "                assert all([output_target[field] is None for field in fields])\n",
    "                for field in fields:\n",
    "                    output_target[field] = output_target['group']\\\n",
    "                        .create_dataset(\n",
    "                            field,\n",
    "                            data=data[field],\n",
    "                            maxshape=(None,)+data[field].shape[1:]\n",
    "                            )\n",
    "            else:\n",
    "                assert all([output_target[field] is not None for field in fields])\n",
    "                for field in fields:\n",
    "                    output_target[field].resize(\n",
    "                        output_target[field].shape[0] + data[field].shape[0],\n",
    "                        axis=0\n",
    "                    )\n",
    "                    output_target[field][-data[field].shape[0]:] = data[field]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "<HDF5 dataset \"body\": shape (10,), type \"|O\">\n",
      "<HDF5 dataset \"mask\": shape (10, 64), type \"<i8\">\n",
      "<HDF5 dataset \"sentence\": shape (10, 768), type \"<f4\">\n",
      "<HDF5 dataset \"word\": shape (10, 64, 768), type \"<f4\">\n",
      "\n",
      "Testing data:\n",
      "<HDF5 dataset \"body\": shape (1,), type \"|O\">\n",
      "<HDF5 dataset \"mask\": shape (1, 64), type \"<i8\">\n",
      "<HDF5 dataset \"sentence\": shape (1, 768), type \"<f4\">\n",
      "<HDF5 dataset \"word\": shape (1, 64, 768), type \"<f4\">\n",
      "\n",
      "Text samples:\n",
      "8. b'eagle'\n",
      "\n",
      "5. b'flying disc'\n",
      "\n",
      "4. b'dvd'\n",
      "\n",
      "array([-0.5917937 ,  0.12636021,  0.74226815, ..., -0.16075838,\n",
      "        0.36404175,  1.2876865 ], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "with h5py.File(PrepConfig.H5DSET_TEST_PATH, 'r') as f:\n",
    "    print(\"Training data:\")\n",
    "    for k in f['training']:\n",
    "        print(repr(f['training'][k]))\n",
    "    print(\"\\nTesting data:\")\n",
    "    for k in f['testing']:\n",
    "        print(repr(f['testing'][k]))\n",
    "    print(\"\\nText samples:\")\n",
    "    for i in random.sample(range(f['training']['body'].shape[0]), 3):\n",
    "        print(f\"{i}. {f['training']['body'][i]}\\n\")\n",
    "    with np.printoptions(threshold=100):\n",
    "        print(repr(f['training']['sentence'][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "31"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "from transformers import DistilBertConfig, DistilBertTokenizerFast\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from config import TrainConfig\n",
    "\n",
    "class Text2EmojiModel(torch.nn.Module):\n",
    "    EOS_TOKEN = '[EOS]'\n",
    "    sentence_onnx = create_model_for_provider(PrepConfig.SENTENCE_ONNX_PATH, \"CUDAExecutionProvider\")\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained(TrainConfig.DISTILBERT_NAME)\n",
    "\n",
    "\n",
    "    def __init__(self, emoji_vocab:list, device:torch.device):\n",
    "        super(Text2EmojiModel, self).__init__()\n",
    "        self.emoji_vocab = emoji_vocab + [self.EOS_TOKEN]\n",
    "        self.config = DistilBertConfig()\n",
    "        self.encoder_head = torch.nn.TransformerEncoder(\n",
    "            encoder_layer=torch.nn.TransformerEncoderLayer(\n",
    "                d_model=self.config.dim,\n",
    "                nhead=self.config.n_heads,\n",
    "            ),\n",
    "            num_layers=1,\n",
    "        )\n",
    "        self.classification = torch.nn.Linear(self.config.dim, len(self.emoji_vocab))\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        '''\n",
    "        args:\n",
    "            x: distilbert embeddings of shape (SEQ_LEN, BATCH_SIZE, HIDDEN_DIM)\n",
    "            mask: attention mask of shape (BATCH_SIZE, SEQ_LEN)\n",
    "        \n",
    "        returns:\n",
    "            token classification logits: (MAX_SEQ_LEN, BATCH_SIZE, EMOJI_VOCAB_SIZE)\n",
    "        '''\n",
    "        mask = ~mask.bool()\n",
    "        # Note: Huggingface masks attends to 1 and ignore 0, pytorch attends to True and ignores False\n",
    "        _x = self.encoder_head(\n",
    "            src=x,\n",
    "            src_key_padding_mask=mask,\n",
    "        )\n",
    "        # print(_x.shape)  # (SEQ_LEN, BATCH_SIZE, HIDDEN_DIM)\n",
    "        zeros = torch.zeros(\n",
    "                min(TrainConfig.MAX_EMOJI_SENTENCE_LEN-_x.shape[0], _x.shape[0]), \n",
    "                _x.shape[1], \n",
    "                _x.shape[2], \n",
    "                device=self.device,\n",
    "                requires_grad=True\n",
    "                )\n",
    "        _x = torch.cat(\n",
    "            (_x, zeros),\n",
    "            dim=0,\n",
    "        )\n",
    "        # print(_x.shape)  # (MAX_SEQ_LEN, BATCH_SIZE, HIDDEN_DIM)\n",
    "        _x = self.classification(_x)\n",
    "        # print(_x.shape)  # (MAX_SEQ_LEN, BATCH_SIZE, EMOJI_VOCAB_SIZE)\n",
    "        return _x\n",
    "\n",
    "\n",
    "    def embedding_to_emojis(self, x, debug=False) -> List[str]:\n",
    "        '''\n",
    "        args:\n",
    "            x: one of self.forward outputs of shape (MAX_SEQ_LEN, EMOJI_VOCAB_SIZE)\n",
    "\n",
    "        returns:\n",
    "            list[str], float of shape (<=MAX_SEQ_LEN,), 0\n",
    "        '''\n",
    "        output = []\n",
    "        m = torch.distributions.categorical.Categorical(logits=x, validate_args=True)\n",
    "        s = m.sample()\n",
    "        log_prob = m.log_prob(s)\n",
    "        last = len(s)\n",
    "        if debug:\n",
    "            logging.info(\"embedding_to_emojis: \")\n",
    "            logging.info(f\"sample: {s}\")\n",
    "            torch.manual_seed(0)\n",
    "        for i in range(len(s)):\n",
    "            token_id = s[i]\n",
    "            token = self.emoji_vocab[token_id]\n",
    "            if debug:\n",
    "                logging.info(f\"token: {token}, token_id: {token_id}\")\n",
    "            if token == self.EOS_TOKEN:\n",
    "                last = i+1\n",
    "                break\n",
    "            output.append(token)\n",
    "        if debug:\n",
    "            logging.info(f\"last: {last}\")\n",
    "        return (output, torch.unsqueeze(torch.sum(log_prob[:last]),-1))\n",
    "        \n",
    "    \n",
    "    def embeddings_to_emojis(self, x, debug=False) -> List[List[str]]:\n",
    "        '''\n",
    "        args:\n",
    "            x: self.forward outputs of shape (MAX_SEQ_LEN, BATCH_SIZE, EMOJI_VOCAB_SIZE)\n",
    "        \n",
    "        returns:\n",
    "            list[list[str]], list[float] of shape (BATCH_SIZE, <=MAX_SEQ_LEN), (BATCH_SIZE,)\n",
    "        '''\n",
    "        emojis = []\n",
    "        log_probs = None\n",
    "        if debug:\n",
    "            logging.info(\"embeddings_to_emojis: \")\n",
    "            logging.info(f\"x shape: {x.shape}\")\n",
    "        for i in range(x.shape[1]):\n",
    "            emoji, log_prob = self.embedding_to_emojis(x[:, i, :], debug=debug)\n",
    "            if debug:\n",
    "                logging.info(f\"log_prob shape: {log_prob.shape}\")\n",
    "            emojis.append(emoji)\n",
    "            if log_probs is None:\n",
    "                log_probs = (log_prob)\n",
    "            else:\n",
    "                log_probs = torch.cat([log_probs, log_prob])\n",
    "        return emojis, log_probs\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def emojis_to_sentence_embedding(self, x, debug=False):\n",
    "        '''\n",
    "        args:\n",
    "            x: embeddings_to_emojis outputs of shape (BATCH_SIZE, MAX_SEQ_LEN, EMOJI_VOCAB_SIZE)\n",
    "        \n",
    "        returns:\n",
    "            array of shape (BATCH_SIZE, SENTENCE_EMBEDDING_DIM)\n",
    "        '''\n",
    "        x = [\" \".join(y) for y in x]\n",
    "        inputs = self.tokenizer(\n",
    "            x, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='np'\n",
    "            )\n",
    "        if debug:\n",
    "            logging.info(\"emojis_to_sentence_embeddings: \")\n",
    "            logging.info(f\"inputs shape: {inputs.shape}\")\n",
    "        _x = self.sentence_onnx.run(None, dict(inputs))\n",
    "        _x = self.mean_pooling(_x, inputs['attention_mask'])\n",
    "        return _x\n",
    "\n",
    "\n",
    "    def embeddings_to_emojis_to_sentence_embeddings(self, x, debug=False):\n",
    "        emojis, log_prob = self.embeddings_to_emojis(x, debug=debug)\n",
    "        _x = self.emojis_to_sentence_embedding(emojis, debug=debug)\n",
    "        return torch.from_numpy(_x).float().to(self.device), log_prob, emojis\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pooling(x, attention_mask):\n",
    "        '''\n",
    "        args:\n",
    "            x: sentence transformer last layer outputs of shape (1, BATCH_SIZE, SEQ_LEN, HIDDEN_DIM_SIZE)\n",
    "\n",
    "        returns:\n",
    "            mean of last layer outpus across SEQ_LEN, taking attention mask into account\n",
    "        '''\n",
    "        token_embeddings = x[0]\n",
    "        assert isinstance(token_embeddings, np.ndarray)\n",
    "        if isinstance(attention_mask, np.ndarray):\n",
    "            input_mask_expanded = np.tile(np.expand_dims(attention_mask, axis=-1), (1, 1, token_embeddings.shape[-1])).astype('float32')\n",
    "        else:\n",
    "            assert isinstance(attention_mask, torch.tensor)\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.shape).float()\n",
    "        sum_embeddings = np.sum(token_embeddings * input_mask_expanded, axis=1)\n",
    "        sum_mask = np.clip(np.sum(input_mask_expanded, axis=1), a_max=None, a_min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "\n",
    "if False:\n",
    "    dummy_vocab = ['a', 'b', 'c']\n",
    "    dummy_input = torch.rand(64, 3, 768)\n",
    "    dummy_mask = torch.cat((torch.ones(3, 32), torch.zeros(3, 32)), dim=1)\n",
    "    model = Text2EmojiModel(dummy_vocab, 'cpu')\n",
    "    param = ''\n",
    "    for name, _ in model.named_parameters():\n",
    "        if name != param:\n",
    "            param = name\n",
    "            print(name)\n",
    "    output = model(dummy_input, dummy_mask)\n",
    "    print(output.shape)\n",
    "    embed, log_prob = model.embeddings_to_emojis_to_sentence_embeddings(output)\n",
    "    print(embed.shape)\n",
    "    print(log_prob.shape)\n",
    "    del dummy_input, dummy_vocab, dummy_mask, model, param, output, embed, log_prob\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([2, 4, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[0, 1, 2, 3, 4],\n",
      "         [0, 1, 2, 3, 4],\n",
      "         [0, 1, 2, 3, 4]],\n",
      "\n",
      "        [[5, 6, 7, 8, 9],\n",
      "         [5, 6, 7, 8, 9],\n",
      "         [5, 6, 7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dist = torch.tensor([\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.0, 1.0],\n",
    "        [0.3, 0.7],\n",
    "    ],\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [1.0, 0.0],\n",
    "        [0.3, 0.7],\n",
    "    ],\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [0.0, 1.0],\n",
    "        [0.3, 0.7],\n",
    "    ],\n",
    "    [\n",
    "        [0.5, 0.5],\n",
    "        [1.0, 0.0],\n",
    "        [0.3, 0.7],\n",
    "    ]\n",
    "])\n",
    "\n",
    "print(dist.size())\n",
    "m = torch.distributions.Categorical(logits=dist)\n",
    "s = m.sample((2,))\n",
    "logprob = m.log_prob(s)\n",
    "print(s.shape)\n",
    "lens = torch.tensor([\n",
    "    [[1,1,1,1],\n",
    "    [2,2,2,2]]\n",
    "])\n",
    "print(torch.arange(s.shape[-1]).view(1, s.shape[-1])\\\n",
    "    .repeat(s.shape[0], s.shape[1], 1).shape)\n",
    "mask = torch.arange(s.shape[-1]).view(1, s.shape[-1]).repeat(s.shape[0], s.shape[1], 1) < lens.view(s.shape[0], s.shape[1], 1)\n",
    "# print((logprob*mask).sum(-1))\n",
    "# print(f\"Sample: {s}\")\n",
    "# # print(f\"Sample size: {s.size()}\")\n",
    "# print(f\"Mask: {mask}\")\n",
    "# print(f\"Log prob: {logprob}\")\n",
    "# print(f\"Masked log prob: {mask*logprob}\")\n",
    "print(torch.arange(10).view(2,5).repeat(3, 1, 1).transpose(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "\n",
    "class Text2EmojiDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.h5dest = h5py.File(PrepConfig.H5DSET_PATH, 'r')['training']\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "        # return self.h5dest['word'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        '''\n",
    "        returns:\n",
    "            (mask, word_embedding, sentence_embedding)\n",
    "        '''\n",
    "        return (\n",
    "            self.h5dest['body'][i],\n",
    "            torch.tensor(self.h5dest['mask'][i], requires_grad=True, dtype=torch.float32), \n",
    "            torch.tensor(self.h5dest['word'][i], requires_grad=True, dtype=torch.float32),\n",
    "            torch.tensor(self.h5dest['sentence'][i], requires_grad=True, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "class TestDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.h5dest = h5py.File(PrepConfig.H5DSET_TEST_PATH, 'r')['training']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.h5dest['word'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        '''\n",
    "        returns:\n",
    "            (body, mask, word_embedding, sentence_embedding)\n",
    "        '''\n",
    "        return (\n",
    "            self.h5dest['body'][i],\n",
    "            torch.tensor(self.h5dest['mask'][i], requires_grad=True, dtype=torch.float32), \n",
    "            torch.tensor(self.h5dest['word'][i], requires_grad=True, dtype=torch.float32),\n",
    "            torch.tensor(self.h5dest['sentence'][i], requires_grad=True, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 90\n",
      "Validation dataset size: 10\n",
      "Training...\n",
      "Please view on tensorboard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:14<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import TrainConfig\n",
    "\n",
    "!rm -rf runs/*\n",
    "\n",
    "logging.root.setLevel(logging.NOTSET)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_printoptions(precision=None, threshold=100, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Set up dataset\n",
    "dset = Text2EmojiDataSet()\n",
    "train_set, val_set = torch.utils.data.random_split(\n",
    "    dset,\n",
    "    lengths=[\n",
    "        math.ceil(len(dset)*(1-TrainConfig.VAL_SPLIT)), \n",
    "        math.floor(len(dset)*TrainConfig.VAL_SPLIT)\n",
    "        ]\n",
    "    )\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=TrainConfig.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=TrainConfig.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
    "\n",
    "# Setup model\n",
    "emoji_vocab = pd.read_csv(TrainConfig.EMOJI_VOCAB_PATH, usecols=['cleaned_name'])['cleaned_name'].to_list()\n",
    "model = Text2EmojiModel(emoji_vocab, device).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), \n",
    "    lr=TrainConfig.LEARNING_RATE,\n",
    "    momentum=0.95)\n",
    "\n",
    "# print(model)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, \n",
    "    step_size=TrainConfig.SCHEDULER_STEP_SIZE, \n",
    "    gamma=TrainConfig.SCHEDULER_GAMMA)\n",
    "\n",
    "try:\n",
    "    print('Training...', flush=True)\n",
    "    print('Please view on tensorboard...', flush=True)\n",
    "    rewards_history = []\n",
    "    for epoch in tqdm(range(TrainConfig.EPOCHS)):\n",
    "\n",
    "        writer.add_scalar('learning rate',\n",
    "                        scheduler.get_last_lr()[0],\n",
    "                        epoch * len(train_loader))\n",
    "\n",
    "        running_loss = .0\n",
    "        running_setence_reward = .0\n",
    "        running_length_reward = .0\n",
    "        emoji_length = .0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            body, mask, x, y = data\n",
    "            mask, x, y = mask.to(device), x.to(device), y.to(device)\n",
    "            x = torch.transpose(x, 0, 1)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(x, mask)\n",
    "            y_pred, log_prob, emojis = model.embeddings_to_emojis_to_sentence_embeddings(outputs)\n",
    "            sentence_reward = -torch.mean((y_pred - y) ** 2, -1)\n",
    "            length_reward = -(torch.tensor(list(map(len, emojis))).to(device) ** 2) * TrainConfig.SHORT_EMOJI_REWARD\n",
    "            reward = sentence_reward + length_reward\n",
    "            expected_reward = np.average(rewards_history) if len(rewards_history) > 0 else 0\n",
    "\n",
    "            loss = torch.mean(-log_prob * (reward-expected_reward))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            rewards_history.append(torch.mean(reward).detach().cpu().numpy())\n",
    "            rewards_history = rewards_history[-TrainConfig.REWARD_HISTORY_LEN:]\n",
    "            running_loss += loss.item()\n",
    "            running_setence_reward += torch.mean(sentence_reward.float()).detach().cpu().numpy()\n",
    "            running_length_reward += torch.mean(length_reward.float()).detach().cpu().numpy()\n",
    "            emoji_length += sum(map(len, emojis))/len(emojis)\n",
    "            if i % TrainConfig.BATCH_PER_LOG == TrainConfig.BATCH_PER_LOG - 1:\n",
    "                # Log the running loss\n",
    "                mean_loss = running_loss / TrainConfig.BATCH_PER_LOG\n",
    "                writer.add_scalar('Train/loss',\n",
    "                                mean_loss,\n",
    "                                epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Train/emoji length',\n",
    "                                    emoji_length / TrainConfig.BATCH_PER_LOG,\n",
    "                                epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Train/expected reward',\n",
    "                                    np.average(rewards_history),\n",
    "                                epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Train/sentence reward',\n",
    "                                    running_setence_reward / TrainConfig.BATCH_PER_LOG,\n",
    "                                epoch * len(train_loader) + i)\n",
    "                writer.add_scalar('Train/length reward',\n",
    "                                    running_length_reward / TrainConfig.BATCH_PER_LOG,\n",
    "                                epoch * len(train_loader) + i)\n",
    "                if mean_loss < 500:\n",
    "                    writer.add_text('low loss examples',\n",
    "                                    \" \".join(emojis[0]),\n",
    "                                    epoch * len(train_loader) + i)\n",
    "                with torch.no_grad():\n",
    "                    val_loss = .0\n",
    "                    for body_val, mask_val, x_val, y_val in val_loader:\n",
    "                        mask_val = mask_val.to(device)\n",
    "                        x_val = x_val.to(device)\n",
    "                        y_val = y_val.to(device)\n",
    "                        x_val = torch.transpose(x_val, 0, 1)\n",
    "                        outputs_val = model(x_val, mask_val)\n",
    "                        y_pred_val, log_prob_val, emojis_val = model.embeddings_to_emojis_to_sentence_embeddings(outputs_val, debug=False)\n",
    "                        reward_val = -torch.mean((y_pred_val - y_val) ** 2, -1)\n",
    "                        loss_val = torch.mean(log_prob_val * (reward_val))\n",
    "                        val_loss += loss_val.item()\n",
    "                    mean_val_loss = val_loss/len(val_loader)\n",
    "                    writer.add_scalar(\n",
    "                        'Validation/loss', \n",
    "                        mean_val_loss, \n",
    "                        epoch * len(train_loader) + i)\n",
    "                    writer.add_scalar(\n",
    "                        'Validation/emoji length', \n",
    "                        sum(map(len, emojis_val)) / len(val_loader), \n",
    "                        epoch * len(train_loader) + i)\n",
    "                running_loss = .0\n",
    "                running_setence_reward = .0\n",
    "                running_length_reward = .0\n",
    "                emoji_length = .0\n",
    "            \n",
    "        scheduler.step()\n",
    "    gc.collect()\n",
    "    print(\"Done!\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    traceback.print_exc()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6  ('.venv': venv)",
   "name": "pythonjvsc74a57bd064b05639d153cffc25231740a168d1c82569538952cc32e6f4539120173a9ef4"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "64b05639d153cffc25231740a168d1c82569538952cc32e6f4539120173a9ef4"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}